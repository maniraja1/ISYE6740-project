{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dd230ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "62a3e8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv(\"Xray_TeethLabels_Simple.csv\",index_col=0)\n",
    "Ylabels = labels[5:]\n",
    "metaY = labels[:3]\n",
    "X = pd.DataFrame()\n",
    "Y = []\n",
    "for picFilename in glob.glob(\"processed3/processed/*\"):\n",
    "    #print(picFilename)\n",
    "    patNumber = picFilename.split('/')[2].split('_')[0]\n",
    "    #toothNumber = picFilename.split('/')[2].split('_')[1].split('.')[0]\n",
    "    toothNumber1 = picFilename.split('/')[2].split('_')[1]\n",
    "    toothNumber2 = picFilename.split('/')[2].split('_')[2].split('.')[0]\n",
    "    im = Image.open(picFilename)\n",
    "    #X[patNumber + '_' + toothNumber] = np.array(im).flatten()\n",
    "    #Y.append(Ylabels.loc[toothNumber,patNumber])\n",
    "    \n",
    "    X[patNumber + '_' + toothNumber1 + '_' + toothNumber2] = np.array(im).flatten()\n",
    "    if Ylabels.loc[toothNumber1,patNumber] == 'Yes' or Ylabels.loc[toothNumber2,patNumber] == 'Yes':\n",
    "        Y.append(1)\n",
    "    else:\n",
    "        Y.append(0)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X.T.to_numpy(), np.array(Y), test_size=0.20, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b69de4de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best value for C is: {'C': 0.1, 'kernel': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "def svc_param_selection(X, y, nfolds):\n",
    "    C = [0.1, 1, 10, 100, 1000] #try different values for C\n",
    "    kernel = ['linear', 'rbf']\n",
    "    param_grid = {'C': C, 'kernel': kernel}\n",
    "    grid_search = GridSearchCV(SVC(), param_grid, cv=nfolds)\n",
    "    grid_search.fit(X, y)\n",
    "    grid_search.best_params_\n",
    "    return grid_search.best_params_\n",
    "best_c = svc_param_selection(X.T.to_numpy(), np.array(Y), 2)\n",
    "print (\"The best value for C is:\",best_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6c62d8f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=0.1, kernel='linear')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.67      0.69        15\n",
      "           1       0.75      0.79      0.77        19\n",
      "\n",
      "    accuracy                           0.74        34\n",
      "   macro avg       0.73      0.73      0.73        34\n",
      "weighted avg       0.73      0.74      0.73        34\n",
      "\n",
      "[[10  5]\n",
      " [ 4 15]]\n"
     ]
    }
   ],
   "source": [
    "model = SVC(C=best_c['C'], kernel=best_c['kernel'])\n",
    "model.fit(X_train, y_train)\n",
    "print(model)\n",
    "# make predictions\n",
    "expected = y_test\n",
    "predicted = model.predict(X_test)\n",
    "# summarize the fit of the model\n",
    "print(metrics.classification_report(expected, predicted))\n",
    "print(metrics.confusion_matrix(expected, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08040b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "15\n",
      "5\n",
      "4\n",
      "sensitivity: 0.7894736842105263\n",
      "Specificity: 0.6666666666666666\n",
      "FPR: 0.3333333333333333\n",
      " FNR: 0.21052631578947367\n",
      "Accuracy: 0.7352941176470589\n",
      "precision: 0.75\n",
      "Recall: 0.7894736842105263\n",
      "F1 score: 0.7692307692307692\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = metrics.confusion_matrix(y_test, predicted).ravel()\n",
    "print(tn)\n",
    "print(tp)\n",
    "print(fp)\n",
    "print(fn)\n",
    "print(f\"sensitivity: {tp/(tp+fn)}\")\n",
    "print(f\"Specificity: {tn/(tn+fp)}\")\n",
    "print(f\"FPR: {fp/(fp+tn)}\")\n",
    "print(f\" FNR: {fn/(fn+tp)}\")\n",
    "print(f\"Accuracy: {(tp+tn)/(tp+tn+fp+fn)}\")\n",
    "precision = tp/(tp+fp)\n",
    "recall = tp/(tp+fn)\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 score: {(2*precision*recall)/(precision+recall)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fd3b64",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
